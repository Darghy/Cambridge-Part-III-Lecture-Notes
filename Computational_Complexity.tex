\documentclass{article}
%build with recipe latexmk
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{fancyhdr}
\pagestyle{fancy}

\usepackage{tcolorbox}
\tcbuselibrary{theorems}
\usepackage{babel}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
%\usepackage{a4wide}
\usepackage{float}
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{setspace}
\setstretch{1.1}
\usepackage{color}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{example}{Example}[section]
\newtheorem{defn}{Definition}[section]

\title{Part III \\ Introduction to Computational Complexity
    \\ \large
    Lectured by Timothy Gowers 
}
 
\author{Artur Avameri}
\date{}
 
\setcounter{section}{-1}
 
\begin{document}
\maketitle
\tableofcontents
\newpage
 
\section{Introduction}
 
A good book for the course is the first few chapters of \textit{Computational Complexity: A modern approach} by Arora and Barack.

\subsection{Computational problems}

A problem in complexity theory is somewhat different from a mathematical problem -- it is more like a class of problems.
\begin{example}
    Given: A graph $G$ with $n$ vertices and $x,y \in V(G)$. Problem: Is there a path from $x$ to $y$? This is a decision problem (yes/no answer).
\end{example}
A problem has a variable input and an output. If the output belongs to $\{0,1\}$, i.e. $\{\text{no, yes}\}$, then the problem is called a \textbf{decision problem}. Write $\{0,1\}^*$ for the set of $\bigcup_{n=1}^\infty \{0,1\}^n$. Then a decision problem can be encoded as a \textbf{Boolean function}, that is, a function $f : \{0,1\}^* \to \{0,1\}$.
\vspace{1mm}
 
The set $\{x \in \{0,1\}^* \mid f(x) = 1\}$ is called the \textbf{language} defined by $f$.

\subsection{Turing machines}

A \textbf{Turing machine} formalizes the notion of an algorithm. There are many ways to formalize it -- we (handwavily) describe a few.
\vspace{1mm}
 
A \textbf{$k$--tape Turing machine} consists of several ingredients. The first is a collection of $k$ \textbf{tapes}, where a tape is an infinite sequence of \textbf{cells}. There is also a finite set $A$ called the \textbf{alphabet}, and each cell contains an element of $A$. There is also a \textbf{head} which is in a \textbf{state} (an element of a finite set $S$ of states) and in a \textbf{position} in each state. $S$ contains two special states, $S_{\text{init}}$ and $S_{\text{halt}}$. 
\vspace{1mm}
 
A state is a function that takes as input an element of $A^k \times S$ and outputs an element of $A^k \times S \times \{L, N, R\}^k$. If $S$ is this ''transition function'', then the machine rewrites $(a_1,\ldots,a_k)$ according to the $A^k$ component of the image, changes the state of the head according to the $S$ component, and shifts each tape according to the $\{L,N,R\}^k$ component.
\vspace{1mm}
 
One tape is designated as the input tape and is never changed, another is the output tape. All tapes other than the input tape start full of zeroes. If the machine reaches the state $S_{\text{halt}}$, it stops. If the input is $x$ and the output is $y$, we say that the machine computed $y$ given input $x$.
\vspace{1mm}
 
\textbf{Variants} assume that $A = \{0,1\}$; that $k=1$ (with a different convention about input--output tapes); that tapes are two--sided, etc.

\section{Some complexity classes}

\begin{defn}
    The complexity class P consists of all Boolean functions (i.e. problems) $f: \{0,1\}^* \to \{0,1\}$ such that there exists a Turing machine $T$ and a polynomial $p$ such that for every $x \in \{0,1\}^*$, $T$ computes $f(x)$ in at most $p(|x|)$ steps, where $|x| = m$ if $x \in \{0,1\}^m$.
\end{defn}

\begin{example}
    The problem st-CONN (input: directed graph $G$ and two vertices $s,t$; output: $1$ if there is a directed path from $s$ to $t$) belongs to $P$.
\end{example}
\begin{example}
    Input: positive integers $m,n$ and output: $mn$. This is polynomial in the number of digits.
\end{example}
\marginpar{23 Jan 2024, Lecture 2}

We now talk about NP, which stands for nondeterministic polynomial time.
\begin{example}
    Input: a graph $G$ with $n$ vertices. Output: 1 iff $G$ contains a Hamilton cycle (a cycle that contains every vertex).
\end{example}
Loosely, a nondeterministic algorithm is one that doesn't fully specify what it does. It outputs $f(x)=1$ if there is some sequence of choices that leads to $f(x)=1$. More formally, a \textbf{nondeterministic Turing machine} is one that has not one but two transition functions. At each step, it applies one or the other. We say that it computes $f$ if $f(x)=1 \iff$ there is some sequence of choices that leads to output $1$ when the input is $x$.
\begin{defn}
    NP is the class of functions computable in polynomial time by a nondeterministic Turing machine.
\end{defn}
\begin{defn}[Alternative definition]
    $f \in $ NP $\iff$ there is a polynomial $p$ and a function $g \in$ P such that for every $x \in \{0,1\}^{*},~ \exists y \in \{0,1\}^{p(|x|)}$ such that $g(x,y)=1$.
\end{defn}
To see that this is equivalent, observe first that if $f$ satisfies the second definition, then we can write down $y$ nondeterministically and apply $g$. In the other direction, $y$ encodes choices made by the NDTM, so given $y$, the computation can be done deterministically.
\vspace{1mm}
 
Big open problem: does P = NP?

\begin{defn}[co--NP]
    $f \in \text{co--NP} \iff 1-f \in$ NP.
    \vspace{1mm}
     
    Alternatively, $f \in \text{co--NP} \iff$ there exists a polynomial $p$ and $g \in P$ such that $\forall x \in \{0,1\}^*$, $f(x)=1 \iff ~\forall y \in \{0,1\}^{p(|x|)}, g(x,y)=1$.
\end{defn}
For example, primality testing is in both NP and co--NP (for co--NP, we need to find a polynomial time algorithm that verifies a number is prime, see Ex. Sheet 1).
\vspace{1mm}
 
\subsection{The polynomial hierarchy}

\begin{defn}
    Define $\Sigma_{0}^P$ and $\Pi_0^P$ to be $P$. If $\Sigma_{k}^P$ and $\Pi_k^P$ have been defined, then $f \in \Sigma_{k+1}^P$ $\iff \exists $ a polynomial $p$ and $g \in \Pi_k^P$ such that $f(x)=1 \iff \exists y, g(x,y) = 1$. 
    \vspace{1mm}
     
    Also $f \in \Pi_{k+1}^P$ $\iff \exists $ a polynomial $p$ and $g \in \Sigma_k^P$  such that $f(x)=1 \iff \forall  y, g(x,y) = 1$ (here $y \in \{0,1\}^{p(x)}$).
\end{defn}
\begin{example}
    $f \in \Sigma_{5}^P \iff \exists h \in P$ such that $$f(x)=1 \iff \exists y_1 ~\forall y_2 \exists y_3 ~\forall y_4 \exists y_5, h(y_1,y_2,y_3,y_4,y_5)=1.$$
\end{example}
We define PH (the polynomial hierarchy) as \[
\text{PH} = \bigcup_{k=0}^{\infty} \Sigma_k^P \cup \Pi_k^P.
\]
\begin{prop}
    If P = NP, then $\text{P} = \text{PH}$.
\end{prop}
\begin{proof}
    Note first that if P = NP, then P $= \text{co--NP}$. If $f \in \Sigma_{k+1}^P$, then $\exists g \in \Pi_k^P$ such that $f(x)=1 \iff \exists y~ g(x,y)=1$. By induction, $g \in P$, so $f \in $ NP, so $f \in $ P. The proof for $\Pi_{k+1}^P$ is similar, just look at the negation.
\end{proof}
Exercises on Ex. Sheet 1: 
\begin{itemize}
    \item If $\text{NP} = \text{co--NP}$, then $\text{PH} = \text{NP} = \text{co--NP}$.
    \item If $\Sigma_k^P = \Sigma_{k+1}^P$ or $\Sigma_k^P = \Pi_k^P$, then $\text{PH} = \Sigma_k^P$.
\end{itemize}

\vspace{1mm}
 
\textbf{PSPACE}. This consists of functions that can be computed by a Turing machine that uses only a polynomial amount of tape.
\begin{prop}
    $\text{NP} \subset \text{PSPACE}$.
\end{prop}
Again a reminder: all proofs involving Turing machines are really more proof sketches.
\begin{proof}
    If $f(x)=1 \iff \exists y~g(x,y)=1$ for $g \in P$, then compute $f$ by a brute--force search. All we need to remember is which $y$ we've got to (in any sensible ordering) and whether we've found a value of $y$ that works. Note importantly that we can reuse the space needed to compute each $g(x,y)$.
\end{proof}
Exercise on Ex. Sheet 1: $\text{PH} \subset \text{PSPACE}$.
\vspace{1mm}
 
There are functions in PSPACE but not in PH. Good examples are games: "there exists a move I can play such that for any move you play there exists a move that I can play...". For example, take a game of Go with board size $n$ going to infinity to get an example.
\vspace{1mm}
 
\textbf{EXPTIME.} This is the class of functions that can be computed in time $\exp(O(n^k))$ for some $k$.

\marginpar{25 Jan 2024, Lecture 3}

\begin{prop}
    PSPACE $\subset $ EXPTIME.
\end{prop}
\begin{proof}
    Given a Turing machine in the middle of a computation, define its \textbf{configuration} to be its state, position on each tape, and the values in all the cells on the tapes. If $T$ uses only a polynomial amount of space $p(n)$ for input of size $n$ and has $k$ tapes, then the number of possible configurations is at most $|S|\cdot p(n)^k\cdot |A|^{k p(n)}$, where $A$ is our alphabet (usually $\{0,1\}$). Hence if the computation goes on for longer than the above amount of time, then the configuration repeats (by pigeonhole) and so is eventually periodic, so doesn't halt.
\end{proof}
\textbf{NEXPTIME.} $f \in \text{NEXPTIME} \iff \exists g \in \text{EXPTIME}$ with $f(x)=1 \iff \exists y~ g(x,y) = 1$.
\vspace{1mm}
 
\textbf{EXPSPACE.} This is the set of $f$ that can be computed using at most $\exp(p(n))$ space for an input of size $n$.
\vspace{1mm}
 
So far we have $$\text{P} \subset \text{NP} \subset \text{PSPACE} \subset \text{EXPTIME} \subset \text{NEXPTIME} \subset \text{EXPSPACE}.$$

\subsection{Circuit complexity}

A \textbf{circuit} is a directed acyclic graph (DAG) such that each vertex is labeled as an \textbf{input}, an AND gate, an OR gate, or a NOT gate. An input is a vertex of indegree 0, a NOT gate has to have indegree 1. All vertices of indegree >1 are AND gates or OR gates. Vertices of outdegree 0 are \textbf{outputs}. If the vertex preceeding a NOT gate has value $x$, then the vertex at the NOT gate has value $1-x$. The value at an AND gate is the minimum of the values at its predecessors, and the value at an OR gate is the maximum of the values at its predecessors.
\vspace{1mm}
 
Using these rules, we get a well--defined function from $\{0,1\}^{I}$ to $\{0,1\}^{O}$, where $I$ is the set of input vertices and $O$ is the set of output vertices. If every AND and OR gate has indegree $\le k$, then we say that the circuit is of $\text{fan--in} \le k$. Often we restrict to circuits of fan--in $\le 2$.
\vspace{1mm}
 
\textbf{Straight--line computations.} Let $f : \{0,1\}^n \to \{0,1\}$. A straight--line computation of $f$ is a sequence of functions $f_1,f_2,\ldots,f_m$ (we call $m$ the \textbf{length} of the computation) such that $f_i(x) = x_i$ for $1\le i\le n$, and for each $i>n$, either $f_i = f_{j_1} \wedge \ldots \wedge f_{j_k}$ for some $j_1,\ldots,j_k < i$, or $f_i = f_{j_1} \vee \ldots \vee f_{j_k}$ for some $j_1,\ldots,j_k < i$, or $f_i = 1 - f_j$ for some $j<i$, and $f_m = f$.
\vspace{1mm}
 
By considering a total ordering on the vertices of a DAG such that if $v_1 \to v_2$ in the DAG, then $v_1 < v_2$, we see that the smallest circuit that computes $f$ is the smallest length of a straight--line computation that computes $f$.

\begin{lemma}
    Every function $f : \{0,1\}^n \to \{0,1\}$ can be computed by a circuit of size at most exponential in $n$.
\end{lemma}
\begin{proof}
    Left as an exercise on Ex. Sheet 1. 
\end{proof}
\begin{prop}
    Let $f$ be a function that can be computed by a Turing machine $T$ with $k$ tapes in time $t(n)$ for inputs of size $n$. Then there is a family $(C_n)$ of circuits such that $|C_n| = O(t(n)^{k+2})$ and $C_n$ computes $f$ for inputs of size $n$. 
\end{prop}
\begin{proof}
    Let $S = \{s_1,\ldots,s_r\}$ be the set of states of $T$ and assume that the alphabet is $\{0,1\}$. Then we can encode the configuation of $T$ at time $t$ using $\sigma_1(t),\ldots,\sigma_r(t), \pi_{i}^h(t)$ for $1\le i\le t(n),1\le h\le k$ and $v_i^h(t)$, where $\sigma_i(t) = 1 \iff$ T is in state $s_i$ at time $t$, $\pi_i^h(t) = 1 \iff$ the head is in position $i$ on tape $h$ at time $t$, and $v_i^h(t)$ is the value in cell $i$ of tape $h$ at time $t$.
    \vspace{1mm}
     
    Note that $\sigma_i(t) = 1 \iff$ there exist $j\le r$ and $i_1,\ldots,i_k$ such that $\sigma_j(t-1)=1$ and $\pi_{i_b}^h(t-1) = 1$ for $1\le h\le k$ and $\tau(s_j, v_{i_1}^1(t-1), \ldots, v_{i_k}^k(t-1))$ has state component equal to $s_i$ (here $\tau$ is the transition function).  
    \vspace{1mm}
     
    For any given $i_1,\ldots,i_k$, we have a function of $k+1$ variables to evaluate, which we can do with a circuit of bounded size. Hence we can calculate $\sigma_i(t)$ from the previous configuration in time $O((k+1)t(n)^k) = O(t(n)^k)$.
\end{proof}

\end{document}
