\documentclass{article}
%build with recipe latexmk
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{fancyhdr}
\pagestyle{fancy}

\usepackage{tcolorbox}
\tcbuselibrary{theorems}
\usepackage{babel}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
%\usepackage{a4wide}
\usepackage{float}
\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{setspace}
\setstretch{1.1}
\usepackage{color}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{example}{Example}[section]
\newtheorem{defn}{Definition}[section]

\title{Part III \\ Introduction to Computational Complexity
    \\ \large
    Lectured by Timothy Gowers 
}
 
\author{Artur Avameri}
\date{}
 
\setcounter{section}{-1}
 
\begin{document}
\maketitle
\tableofcontents
\newpage
 
\section{Introduction}
 
A good book for the course is the first few chapters of \textit{Computational Complexity: A modern approach} by Arora and Barack.

\subsection{Computational problems}

A problem in complexity theory is somewhat different from a mathematical problem -- it is more like a class of problems.
\begin{example}
    Given: A graph $G$ with $n$ vertices and $x,y \in V(G)$. Problem: Is there a path from $x$ to $y$? This is a decision problem (yes/no answer).
\end{example}
A problem has a variable input and an output. If the output belongs to $\{0,1\}$, i.e. $\{\text{no, yes}\}$, then the problem is called a \textbf{decision problem}. Write $\{0,1\}^*$ for the set of $\bigcup_{n=1}^\infty \{0,1\}^n$. Then a decision problem can be encoded as a \textbf{Boolean function}, that is, a function $f : \{0,1\}^* \to \{0,1\}$.
\vspace{1mm}
 
The set $\{x \in \{0,1\}^* \mid f(x) = 1\}$ is called the \textbf{language} defined by $f$.

\subsection{Turing machines}

A \textbf{Turing machine} formalizes the notion of an algorithm. There are many ways to formalize it -- we (handwavily) describe a few.
\vspace{1mm}
 
A \textbf{$k$--tape Turing machine} consists of several ingredients. The first is a collection of $k$ \textbf{tapes}, where a tape is an infinite sequence of \textbf{cells}. There is also a finite set $A$ called the \textbf{alphabet}, and each cell contains an element of $A$. There is also a \textbf{head} which is in a \textbf{state} (an element of a finite set $S$ of states) and in a \textbf{position} in each state. $S$ contains two special states, $S_{\text{init}}$ and $S_{\text{halt}}$. 
\vspace{1mm}
 
A state is a function that takes as input an element of $A^k \times S$ and outputs an element of $A^k \times S \times \{L, N, R\}^k$. If $S$ is this ''transition function'', then the machine rewrites $(a_1,\ldots,a_k)$ according to the $A^k$ component of the image, changes the state of the head according to the $S$ component, and shifts each tape according to the $\{L,N,R\}^k$ component.
\vspace{1mm}
 
One tape is designated as the input tape and is never changed, another is the output tape. All tapes other than the input tape start full of zeroes. If the machine reaches the state $S_{\text{halt}}$, it stops. If the input is $x$ and the output is $y$, we say that the machine computed $y$ given input $x$.
\vspace{1mm}
 
\textbf{Variants} assume that $A = \{0,1\}$; that $k=1$ (with a different convention about input--output tapes); that tapes are two--sided, etc.

\section{Some complexity classes}

\begin{defn}
    The complexity class P consists of all Boolean functions (i.e. problems) $f: \{0,1\}^* \to \{0,1\}$ such that there exists a Turing machine $T$ and a polynomial $p$ such that for every $x \in \{0,1\}^*$, $T$ computes $f(x)$ in at most $p(|x|)$ steps, where $|x| = m$ if $x \in \{0,1\}^m$.
\end{defn}

\begin{example}
    The problem st-CONN (input: directed graph $G$ and two vertices $s,t$; output: $1$ if there is a directed path from $s$ to $t$) belongs to $P$.
\end{example}
\begin{example}
    Input: positive integers $m,n$ and output: $mn$. This is polynomial in the number of digits.
\end{example}
\marginpar{23 Jan 2024, Lecture 2}

We now talk about NP, which stands for nondeterministic polynomial time.
\begin{example}
    Input: a graph $G$ with $n$ vertices. Output: 1 iff $G$ contains a Hamilton cycle (a cycle that contains every vertex).
\end{example}
Loosely, a nondeterministic algorithm is one that doesn't fully specify what it does. It outputs $f(x)=1$ if there is some sequence of choices that leads to $f(x)=1$. More formally, a \textbf{nondeterministic Turing machine} is one that has not one but two transition functions. At each step, it applies one or the other. We say that it computes $f$ if $f(x)=1 \iff$ there is some sequence of choices that leads to output $1$ when the input is $x$.
\begin{defn}
    NP is the class of functions computable in polynomial time by a nondeterministic Turing machine.
\end{defn}
\begin{defn}[Alternative definition]
    $f \in $ NP $\iff$ there is a polynomial $p$ and a function $g \in$ P such that for every $x \in \{0,1\}^{*},~ \exists y \in \{0,1\}^{p(|x|)}$ such that $g(x,y)=1$.
\end{defn}
To see that this is equivalent, observe first that if $f$ satisfies the second definition, then we can write down $y$ nondeterministically and apply $g$. In the other direction, $y$ encodes choices made by the NDTM, so given $y$, the computation can be done deterministically.
\vspace{1mm}
 
Big open problem: does P = NP?

\begin{defn}[co--NP]
    $f \in \text{co--NP} \iff 1-f \in$ NP.
    \vspace{1mm}
     
    Alternatively, $f \in \text{co--NP} \iff$ there exists a polynomial $p$ and $g \in P$ such that $\forall x \in \{0,1\}^*$, $f(x)=1 \iff ~\forall y \in \{0,1\}^{p(|x|)}, g(x,y)=1$.
\end{defn}
For example, primality testing is in both NP and co--NP (for co--NP, we need to find a polynomial time algorithm that verifies a number is prime, see Ex. Sheet 1).
\vspace{1mm}
 
\subsection{The polynomial hierarchy}

\begin{defn}
    Define $\Sigma_{0}^P$ and $\Pi_0^P$ to be $P$. If $\Sigma_{k}^P$ and $\Pi_k^P$ have been defined, then $f \in \Sigma_{k+1}^P$ $\iff \exists $ a polynomial $p$ and $g \in \Pi_k^P$ such that $f(x)=1 \iff \exists y, g(x,y) = 1$. 
    \vspace{1mm}
     
    Also $f \in \Pi_{k+1}^P$ $\iff \exists $ a polynomial $p$ and $g \in \Sigma_k^P$  such that $f(x)=1 \iff \forall  y, g(x,y) = 1$ (here $y \in \{0,1\}^{p(x)}$).
\end{defn}
\begin{example}
    $f \in \Sigma_{5}^P \iff \exists h \in P$ such that $$f(x)=1 \iff \exists y_1 ~\forall y_2 \exists y_3 ~\forall y_4 \exists y_5, h(y_1,y_2,y_3,y_4,y_5)=1.$$
\end{example}
We define PH (the polynomial hierarchy) as \[
\text{PH} = \bigcup_{k=0}^{\infty} \Sigma_k^P \cup \Pi_k^P.
\]
\begin{prop}
    If P = NP, then $\text{P} = \text{PH}$.
\end{prop}
\begin{proof}
    Note first that if P = NP, then P $= \text{co--NP}$. If $f \in \Sigma_{k+1}^P$, then $\exists g \in \Pi_k^P$ such that $f(x)=1 \iff \exists y~ g(x,y)=1$. By induction, $g \in P$, so $f \in $ NP, so $f \in $ P. The proof for $\Pi_{k+1}^P$ is similar, just look at the negation.
\end{proof}
Exercises on Ex. Sheet 1: 
\begin{itemize}
    \item If $\text{NP} = \text{co--NP}$, then $\text{PH} = \text{NP} = \text{co--NP}$.
    \item If $\Sigma_k^P = \Sigma_{k+1}^P$ or $\Sigma_k^P = \Pi_k^P$, then $\text{PH} = \Sigma_k^P$.
\end{itemize}

\vspace{1mm}
 
\textbf{PSPACE}. This consists of functions that can be computed by a Turing machine that uses only a polynomial amount of tape.
\begin{prop}
    $\text{NP} \subset \text{PSPACE}$.
\end{prop}
Again a reminder: all proofs involving Turing machines are really more proof sketches.
\begin{proof}
    If $f(x)=1 \iff \exists y~g(x,y)=1$ for $g \in P$, then compute $f$ by a brute--force search. All we need to remember is which $y$ we've got to (in any sensible ordering) and whether we've found a value of $y$ that works. Note importantly that we can reuse the space needed to compute each $g(x,y)$.
\end{proof}
Exercise on Ex. Sheet 1: $\text{PH} \subset \text{PSPACE}$.
\vspace{1mm}
 
There are functions in PSPACE but not in PH. Good examples are games: "there exists a move I can play such that for any move you play there exists a move that I can play...". For example, take a game of Go with board size $n$ going to infinity to get an example.
\vspace{1mm}
 
\textbf{EXPTIME.} This is the class of functions that can be computed in time $\exp(O(n^k))$ for some $k$.

\marginpar{25 Jan 2024, Lecture 3}

\begin{prop}
    PSPACE $\subset $ EXPTIME.
\end{prop}
\begin{proof}
    Given a Turing machine in the middle of a computation, define its \textbf{configuration} to be its state, position on each tape, and the values in all the cells on the tapes. If $T$ uses only a polynomial amount of space $p(n)$ for input of size $n$ and has $k$ tapes, then the number of possible configurations is at most $|S|\cdot p(n)^k\cdot |A|^{k p(n)}$, where $A$ is our alphabet (usually $\{0,1\}$). Hence if the computation goes on for longer than the above amount of time, then the configuration repeats (by pigeonhole) and so is eventually periodic, so doesn't halt.
\end{proof}
\textbf{NEXPTIME.} $f \in \text{NEXPTIME} \iff \exists g \in \text{EXPTIME}$ with $f(x)=1 \iff \exists y~ g(x,y) = 1$.
\vspace{1mm}
 
\textbf{EXPSPACE.} This is the set of $f$ that can be computed using at most $\exp(p(n))$ space for an input of size $n$.
\vspace{1mm}
 
So far we have $$\text{P} \subset \text{NP} \subset \text{PSPACE} \subset \text{EXPTIME} \subset \text{NEXPTIME} \subset \text{EXPSPACE}.$$

\subsection{Circuit complexity}

A \textbf{circuit} is a directed acyclic graph (DAG) such that each vertex is labeled as an \textbf{input}, an AND gate, an OR gate, or a NOT gate. An input is a vertex of indegree 0, a NOT gate has to have indegree 1. All vertices of indegree >1 are AND gates or OR gates. Vertices of outdegree 0 are \textbf{outputs}. If the vertex preceeding a NOT gate has value $x$, then the vertex at the NOT gate has value $1-x$. The value at an AND gate is the minimum of the values at its predecessors, and the value at an OR gate is the maximum of the values at its predecessors.
\vspace{1mm}
 
Using these rules, we get a well--defined function from $\{0,1\}^{I}$ to $\{0,1\}^{O}$, where $I$ is the set of input vertices and $O$ is the set of output vertices. If every AND and OR gate has indegree $\le k$, then we say that the circuit is of $\text{fan--in} \le k$. Often we restrict to circuits of fan--in $\le 2$.
\vspace{1mm}
 
\textbf{Straight--line computations.} Let $f : \{0,1\}^n \to \{0,1\}$. A straight--line computation of $f$ is a sequence of functions $f_1,f_2,\ldots,f_m$ (we call $m$ the \textbf{length} of the computation) such that $f_i(x) = x_i$ for $1\le i\le n$, and for each $i>n$, either $f_i = f_{j_1} \wedge \ldots \wedge f_{j_k}$ for some $j_1,\ldots,j_k < i$, or $f_i = f_{j_1} \vee \ldots \vee f_{j_k}$ for some $j_1,\ldots,j_k < i$, or $f_i = 1 - f_j$ for some $j<i$, and $f_m = f$.
\vspace{1mm}
 
By considering a total ordering on the vertices of a DAG such that if $v_1 \to v_2$ in the DAG, then $v_1 < v_2$, we see that the smallest circuit that computes $f$ is the smallest length of a straight--line computation that computes $f$.

\begin{lemma}
    Every function $f : \{0,1\}^n \to \{0,1\}$ can be computed by a circuit of size at most exponential in $n$.
\end{lemma}
\begin{proof}
    Left as an exercise on Ex. Sheet 1. 
\end{proof}
\begin{prop}\label{prop1.5}
    Let $f$ be a function that can be computed by a Turing machine $T$ with $k$ tapes in time $t(n)$ for inputs of size $n$. Then there is a family $(C_n)$ of circuits such that $|C_n| = O(t(n)^{k+2})$ and $C_n$ computes $f$ for inputs of size $n$. 
\end{prop}
\begin{proof}
    Let $S = \{s_1,\ldots,s_r\}$ be the set of states of $T$ and assume that the alphabet is $\{0,1\}$. Then we can encode the configuation of $T$ at time $t$ using $\sigma_1(t),\ldots,\sigma_r(t), \pi_{i}^h(t)$ for $1\le i\le t(n),1\le h\le k$ and $v_i^h(t)$, where $\sigma_i(t) = 1 \iff$ $T$ is in state $s_i$ at time $t$, $\pi_i^h(t) = 1 \iff$ the head is in position $i$ on tape $h$ at time $t$, and $v_i^h(t)$ is the value in cell $i$ of tape $h$ at time $t$.
    \vspace{1mm}
     
    Note that $\sigma_i(t) = 1 \iff$ there exist $j\le r$ and $i_1,\ldots,i_k$ such that $\sigma_j(t-1)=1$ and $\pi_{i_b}^h(t-1) = 1$ for $1\le h\le k$ and $\tau(s_j, v_{i_1}^1(t-1), \ldots, v_{i_k}^k(t-1))$ has state component equal to $s_i$ (here $\tau$ is the transition function).  
    \vspace{1mm}
     
    For any given $i_1,\ldots,i_k$, we have a function of $k+1$ variables to evaluate, which we can do with a circuit of bounded size. Hence we can calculate $\sigma_i(t)$ from the previous configuration in time $O((k+1)t(n)^k) = O(t(n)^k)$. Similarly we can compute each position variable $\pi_i^k(t)$ from the configuration at time $t-1$ with a circuit of size $O(t(n)^k)$, and also each state variable $\sigma_j(t)$. So we can compute the configuration at time $t$ from the configuration at time $t-1$ with a circuit of size $O(t(n)^{k+1})$, so the result follows.
\end{proof}
\marginpar{30 Jan 2024, Lecture 4}
\textbf{P/poly}. This complexity class has three equivalent definitions. We say $f \in \text{P/poly}$ if one of the following (and hence all) holds:
\begin{enumerate}[(i)]
    \item There is a family $(C_n)$ of polynomial size circuits such that $C_n$ computes $f(x)$ when $\left|x \right| = n$. (So trivially, from Proposition 1.5, $\text{P} \subset \text{P/poly}$.)
    \item There is a polynomial $p$ and a sequence $(y_n)$ with $\left|y_n \right| = p(n)$ and a function $g \in \text{P}$ such that $f(x)=1 \iff g(x,y_{\left|x \right|})=1$. (Think of $y_n$ as ''a piece of advice we will give the algorithm'').
    \item There is a sequence $(T_n)$ of Turing machines and a polynomial $p$ such that $T_n$ has $\le p(n)$ states and $T_n$ computes $f(x)$ when $\left|x \right|=n$.
\end{enumerate}
A sequence $(C_n)$ of circuits is \textbf{P-uniform} if there is a polynomial time algorithm that generates it (i.e. given input $1^n := \{\underbrace{1,\ldots,1}_{n \text{ times}}\}$, it outputs $C_n$).
\begin{proof}[Sketch proof of equivalence.]
    (i) $\implies $ (ii): Let $Y_n$ be an encoding of $C_n$ and let $g(x,y)=1$ if the circuit encoded by $y$ outputs 1 with input $x$.
    \vspace{1mm}
     
    (ii) $\implies $ (i): Fix an input size $n$, let $C_n'$ compute $g$ (using our proposition) on inputs of size $n$ and let $C_n$ be $C$ with the last $p(n)$ inputs restricted to $Y_n$.
    \vspace{1mm}
     
    (ii) $\implies $ (iii): Fix $n$. Let $T$ compute $g$ and let $T_n$ be a Turing machine that prints out $Y_n$ and then uses $T$ to compute $g(x,y_n)$.
    \vspace{1mm}
     
    (iii) $\implies $ (ii): Let $y_n$ be an encoding of $T_n$ and let $g(x,y)=1$ if the Turing machine encoded by $y_n$ outputs $1$ with input $x$.
\end{proof}
\section{Search problems and decision problems}
Let $g$ be a Boolean function of two variables. Then we get the decision problem ''Does there exist $y$ such that $g(x,y)=1$?'' and a corresponding \textbf{search problem} ''If there exists $y$ such that $g(x,y)=1$, then find one.''. A solution to a search problem is an algorithm that outputs $y$ such that $g(x,y)=1$ if it exists. 

\begin{prop}
    If P = NP and $f \in $ NP and $f(x)=1 \iff \exists y$ of size $\left|y \right|=p(\left|x \right|)$ with $g(x,y)=1$ for $g \in \text{P}$, then there is a polynomial time algorithm that computes $h : \{0,1\}^* \to \{0,1\}^*$ such that if $f(x)=1$, then $g(x,h(x))=1$.
\end{prop}
\begin{proof}
    For each $i$, let $g_i$ be the function that takes as input $x$ and $u_i$ with $\left|u_i \right|=i$, and outputs 1 if and only if $\exists v$ with $\left|v \right|=p(\left|x \right|)-i$ such that $g(x,u,v)=1$. Now run the following procedure: start by calculating $g_1(x,1)$ in polynomial time (since $\text{P}=\text{NP}$) and let $u_1=g_1(x,1)$. Note that if $\exists y$ such that $g(x,y)=1$, then $\exists v$ such that $g_1(x,u_1,v)=1$. Now let $u_2 = g_2(x, u_1), u_3=g_3(x,u_2)$ and so on. At the end, we obtain $u = (u_1,\ldots,u_{p(\left|x \right|)})$ such that $g(x,u)=1$.
\end{proof}
The idea of this proof is just to play 20 questions: can the first digit be 1? Can the second digit be 1? etc.
\begin{lemma}
    If $\text{NP}\subset \text{P/poly}$, then for $f$ as in the previous proposition, there is a polynomial sized family of circuits $(C_n)$ such that if $\left|x \right|=n$, then $C_n$ with input $x$ computes $y$ such that $g(x,y)=1$. 
\end{lemma}
\begin{proof}
    Use the notation from the previous proof. For each $i$, since $\text{NP}\subset \text{P/poly}$, there is a polynomial sized circuit $C_i'$ that computes $g_i$. Now put together the circuits $C_1',\ldots,C_{p(n)}'$ as follows: $C_1'$ takes inputs $x_1,\ldots,x_n,1$ and outputs $u_1$. $C_2'$ takes inputs $x_1,\ldots,x_n,u_1,1$ and outputs $u_2$. $C_3'$ takes inputs $x_1,\ldots,x_n,u_1,u_2,1$. Continue all the way until $C_{p(n)}'$. Then the output if $\exists y$ such that $g(x,y)=1$ will be such a $y$.
\end{proof}
\begin{theorem}[Karp--Lipton Theorem]
    If $\text{NP}\subset \text{P/poly}$, then $\Sigma_2^P = \pi_2^P$ (and therefore $\text{PH} = \Sigma_2^P = \Pi_2^P$).
\end{theorem}
\marginpar{01 Feb 2024, Lecture 5}
\begin{proof}
    Let $f \in \Pi_2^P$ and $h \in P$ be such that $f(x)=1 \iff ~\forall y ~\exists z ~ {h(x,y,z)=1}$ (for $y,z$ of appropriate polynomial size depending on $\left|x\right|$). Define $g(x,y)$ to be 1 if and only if $\exists z ~h(x,y,z)=1$. Then $g \in \text{NP}$, so by our hypothesis and the lemma above, there is a circuit family $(C_n)$ of polynomial size such that for every $x$, if $\left|x\right|=n$ and $g(x,y)=1$, then $h(x,y,C_n(x,y)) = 1$ (with $C_n(x,y)$ the output of $C_n$ with input $x,y$). So $f(x)=1 \implies \exists C_n ~\forall y ~ h(x,y, C_n(x,y))=1$. Checking whether $h(x,y, C_n(x,y))=1$ can be done in polynomial time. If $f(x)=0$, then $\exists y ~\forall z ~h(x,y,z)=0$, so the $\implies$ is in fact an if and only if. Therefore $f \in \Sigma_2^P$. By doing the same for $1-f$, we get the reverse inclusion.
\end{proof}
\begin{lemma}
    For every $k$, there is a Boolean function $f$ that can be computed by a circuit family of size $n^{k+1}$, but not by a circuit family of size $n^k$.
\end{lemma}
\begin{proof}
    This is on Ex. Sheet 1. Note that Gowers is also pretty happy with a proof for $n^{2k}$, but $n^{k+1}$ can be achieved.
\end{proof}
\begin{theorem}
    For every $k$, there is a Boolean function $f \in \Sigma_4^P$ that cannot be computed by a family of circuits of size $n^k$.
\end{theorem}
\begin{proof}
    For $n$ sufficiently large, the lemma gives us $f'_n : \{0,1\}^n \to \{0,1\}$ that can be computed by a circuit of size $n^{k+1}$, but not by a circuit of size $n^k$. Choose a sensible ordering on circuits of size $\le n^{k+1}$. Let $f_n(x)$ (if $\left|x\right|=n$) be $C_n(x)$, where $C_n$ is the first circuit (in this ordering) such that $\left|C_n\right|\le n^{k+1}$ and no circuit of size $\le n^k$ computes the same function as $C_n$. Then let $f = (f_n)_1^\infty$ (for large enough $n$, for $n<n_0$, let $f_n$ be arbitrary).
    \vspace{1mm}
     
    Then if $\left|x\right|=n$, we have $f(x)=1$ if and only if 
    \begin{align*}
        \exists C_n, \left|C_n\right|\le n^{k+1} \text{ and }~\forall D, \left|D\right|\le n^k, \exists y ~ C_n(y) \neq D(y) \\
        \text{and } ~\forall E, E \prec C_n, \exists F ~ \left|F\right|\le n^k ~\forall z ~ E(z)=F(z) \text{ and }C_n(x)=1.
    \end{align*}
    (Here $E \prec C_n$ means $E$ preceeds $C_n$ in our ordering.) Then $\exists ~\forall \exists ~\forall $ shows that $f \in \Sigma_4^P$.
\end{proof}
\begin{cor}
    In fact, for every $k$ there is a function $f \in \Sigma_2^P \cap \Pi_2^P$ that cannot be computed by a circuit family of size $n^k$.
\end{cor}
\begin{proof}
    By the Karp--Lipton theorem, if $\text{NP} \subset \text{P/poly}$, then $\text{PH} \subset \Sigma_2^P \cap \Pi_2^P$, so the function just defined does the job.
    \vspace{1mm}
     
    If $\text{NP} \not\subset \text{P/poly}$, then we get the stronger result that there is $f \in \Sigma_1^P$ ($=\text{NP}$) that can't be computed by any circuit family of polynomial size.
\end{proof}
\textbf{The complexity class L.} Roughly, $\text{L}$ is the set of functions that can be computed with a logarithmic amount of memory. More formally, $f \in \text{L}$ if there is a Turing machine that computes $f$ with a read--only input tape that contains the input and cannot be modified and a work tape of size $O(\log n)$ for inputs of size $n$. (If we want several outputs instead of 1, then we also have a write--only output tape).
\vspace{1mm}
 
For example, during long multiplication in our head is in $\text{L}$, since we can do the computations digit--by--digit locally.
\vspace{1mm}

\textbf{The complexity class NL}. $\text{NL}$ is like $\text{L}$, except that the Turing machine is nondeterministic. We can also give a certificate definition of $\text{NL}$, but one has to be careful. We say that $f \in \text{NL}$ if there is a Turing machine with a read--only input tape, a work tape of size $O(\log n)$ and a read--once certificate tape (on which the head can only ever stay still or move to the right) such that $f(x)=1$ if and only if there is some $y$ with $\left|y\right|\le p(\left|x\right|)$ that can be put in the certificate tape such that the Turing machine outputs 1.

\begin{prop}
    $\text{NL} \subset \text{P}$.
\end{prop}
\begin{proof}
    \marginpar{06 Feb 2024, Lecture 6}
    Let $f  \in \text{NL}$ and let $T$ be a NDTM that computes a function $f$ and uses a logarithmic amount of space. The \textbf{configuration graph} of $T$ is a directed graph, whose vertices are the configurations, and $\kappa \to \kappa'$ if and only if one of the transition functions takes $\kappa$ to $\kappa'$ in one step. Let $G$ be the configuration graph of $T$. Then $f(x)=1 \iff$ there is a directed path in $G$ from the initial configuration to one such that $T$ has halted with output 1. Since $T$ uses $O(\log n)$ space, the number of vertices of $G$ is polynomial in $n$. But REACHABILITY, the problem of determining whether there is a directed path from a vertex $x$ to a subset $S$ of vertices in a directed graph is easily seen to be in $P$. 
\end{proof}
\textbf{Remark.} $\left|V(G)\right|\le 2^{O(\log n)}\left|S\right|=n^{O(1)}$, giving the polynomial bound in the above.

\subsection{Low--depth computation}
The class of $\text{NC}^i$ (for $i \in \mathbb{Z}_{\ge 0}$) consists of all functions that can be computed by a family of circuits of polynomial size, fan--in 2 and depth $O((\log n)^i)$, where the \textbf{depth} of a circuit is the length of the longest directed path in the associated DAG.
\vspace{1mm}
 
$\text{AC}^i$ is like $\text{NC}^i$, except that unbounded fan--in is allowed. It is an exercise on Ex. Sheet 1 to show that $\text{AC}^i \subset \text{NC}^{i+1}$.
We write $\text{NC} = \bigcup_{i=0}^{\infty} \text{NC}^i, \text{AC} = \bigcup_{i=0}^{\infty} \text{AC}^i$ (which are of course equal, but both names come up in literature).
\vspace{1mm}
 
It is usual to impose a uniformity condition on $\text{NC}^i$. The favored condition is log space uniformity, i.e. $f \in \text{u--NC}^i$ if the circuits can be generated in log space (i.e. $\text{L}$).
\vspace{1mm}
 
Major open problem: is $\text{P} \subset \text{NC}$? In fact, it is not known whether $\text{PH} \subset \text{NC}^1$.

\subsection{Randomized computation}
A function $f$ is in $\text{RP}$ (randomized polynomial time) if there is a polynomial $p$ and a function $g \in \text{P}$ such that if $\left|x\right|=n$ and $m = p(n)$, then \[
\mathbb{P}_{y \in \{0,1\}^m}\left(g(x,y)=1\right) = \begin{cases}
    0 & f(x)=0\\
    \ge \frac{1}{2}&f(x)=1.
\end{cases}
\]
Note that if we run the computation on independent strings $y_1,\ldots,y_k$, then $\mathbb{P}(\exists i~g(x,y_i)=1) = \begin{cases}
    0 & f(x)=0\\
    \ge 1-\frac{1}{2^k}&f(x)=1\ldots
\end{cases}$
So we can make the error probability very small without much cost.
\vspace{1mm}
 
We say $f \in \text{co-RP}$ if $1-f \in\text{RP}$. We write $\text{ZPP} = \text{RP} \cap \text{co-RP}$ ($\text{ZPP}$ stands for zero--error probabilistic polynomial time). 
\vspace{1mm}
 
We say $f \in \text{BPP}$ (bounded--error probabilistic polynomial time) if there exists $g$ as above such that $\mathbb{P}_{y \in \{0,1\}^m}(g(x,y)=f(x))\ge \frac{2}{3}$. Again we can shrink the error probability. To do so, pick some $k$ and calculate $g(x,y_1),\ldots,g(x,y_k)$ for $(y_1,\ldots,y_k)$ independent random elements of $\{0,1\}^m$ and take the majority. The probability of getting the wrong answer is at most $e^{-k/48}$ by Chernoff estimates for the sum of independent Bernoulli random variables.

\begin{cor}
    $\text{BPP} \subset \text{P/poly}$.
\end{cor}
\begin{proof}
    If $k \ge 48n$. then the probability that the majority of $g(x,y_i)$ is wrong is $<2^{-n}$. Therefore, there exist $y_1,\ldots,y_k$ such that for every $x$, the majority vote is correct. This $y_1,\ldots,y_k$ serves as an advice string, together with the function that computes the majority vote.
\end{proof}
\begin{prop}
    $\text{BPP} \subset \Sigma_2^P \cap \Pi_2^P$.
\end{prop}
\begin{proof}
    Let $g$ be such that $\mathbb{P}(g(x,y)=f(x))\ge \frac{2}{3}$. Then we have seen that we can find $h$ such that $\mathbb{P}(h(x,y)=f(x))\ge 1-2^{-n}$ (this $y$ is $48n$ times as long as the previous $y$, call this new length $m$). For each $x$, let $A_x = \{y \in \{0,1\}^m \mid h(x,y)=f(x)\}$.
\end{proof}

\end{document}